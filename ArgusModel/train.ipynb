{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-27T08:08:33.930901Z",
     "iopub.status.busy": "2025-09-27T08:08:33.930418Z",
     "iopub.status.idle": "2025-09-27T08:09:14.841506Z",
     "shell.execute_reply": "2025-09-27T08:09:14.840763Z",
     "shell.execute_reply.started": "2025-09-27T08:08:33.930875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for i,filename in enumerate(filenames):\n",
    "        if i % 5000 == 0:\n",
    "            print(i,os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:09:24.016490Z",
     "iopub.status.busy": "2025-09-27T08:09:24.015915Z",
     "iopub.status.idle": "2025-09-27T08:09:24.021959Z",
     "shell.execute_reply": "2025-09-27T08:09:24.021178Z",
     "shell.execute_reply.started": "2025-09-27T08:09:24.016459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths from your Kaggle dataset\n",
    "CSV_PATH   = \"/kaggle/input/militaryaircraftdetectiondataset/labels_with_split.csv\"\n",
    "IMAGES_DIR = \"/kaggle/input/militaryaircraftdetectiondataset/dataset\"  # folder with all images\n",
    "\n",
    "# Working dir where we'll assemble YOLO data\n",
    "WORK_DIR   = \"/kaggle/working\"\n",
    "YOLO_DIR   = f\"{WORK_DIR}/yolo_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:09:26.502204Z",
     "iopub.status.busy": "2025-09-27T08:09:26.501686Z",
     "iopub.status.idle": "2025-09-27T08:10:35.090611Z",
     "shell.execute_reply": "2025-09-27T08:10:35.089712Z",
     "shell.execute_reply.started": "2025-09-27T08:09:26.502182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip -q install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:10:46.442330Z",
     "iopub.status.busy": "2025-09-27T08:10:46.441628Z",
     "iopub.status.idle": "2025-09-27T08:10:55.587420Z",
     "shell.execute_reply": "2025-09-27T08:10:55.586650Z",
     "shell.execute_reply.started": "2025-09-27T08:10:46.442294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'plane': 0}\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create split directories\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    (Path(YOLO_DIR)/split/\"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (Path(YOLO_DIR)/split/\"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Normalize column names just in case\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# Some datasets use 'valid' -> map to 'val'\n",
    "df[\"split\"] = df[\"split\"].str.lower().replace({\"valid\":\"val\", \"validation\":\"val\"})\n",
    "\n",
    "# Build list of available images (map both stem and filename → full path) to be robust to missing extensions in CSV\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "all_image_paths = []\n",
    "for p in Path(IMAGES_DIR).rglob(\"*\"):\n",
    "    if p.suffix.lower() in valid_exts:\n",
    "        all_image_paths.append(p)\n",
    "\n",
    "by_stem     = {p.stem: p for p in all_image_paths}\n",
    "by_basename = {p.name: p  for p in all_image_paths}\n",
    "\n",
    "def resolve_image_path(name: str):\n",
    "    name = str(name)\n",
    "    # if full basename (with ext) is present\n",
    "    if name in by_basename: \n",
    "        return by_basename[name]\n",
    "    # if only stem is there\n",
    "    stem = Path(name).stem\n",
    "    if stem in by_stem:\n",
    "        return by_stem[stem]\n",
    "    return None\n",
    "\n",
    "df[\"class\"] = \"plane\"\n",
    "# Sanitize class names and build class map (sorted for deterministic ids)\n",
    "df[\"class\"] = df[\"class\"].astype(str).str.strip()\n",
    "class_names = sorted(df[\"class\"].unique().tolist())\n",
    "name_to_id  = {n:i for i,n in enumerate(class_names)}\n",
    "print(\"Classes:\", name_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:11:07.317573Z",
     "iopub.status.busy": "2025-09-27T08:11:07.317195Z",
     "iopub.status.idle": "2025-09-27T08:11:20.892435Z",
     "shell.execute_reply": "2025-09-27T08:11:20.891676Z",
     "shell.execute_reply.started": "2025-09-27T08:11:07.317544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21950/21950 [00:13<00:00, 1622.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with labels written: 21950, missing/failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clip boxes helper\n",
    "def xyxy_to_yolo(xmin, ymin, xmax, ymax, W, H):\n",
    "    # clip to image bounds\n",
    "    xmin = np.clip(xmin, 0, W-1)\n",
    "    ymin = np.clip(ymin, 0, H-1)\n",
    "    xmax = np.clip(xmax, 0, W-1)\n",
    "    ymax = np.clip(ymax, 0, H-1)\n",
    "    bw = max(0.0, xmax - xmin)\n",
    "    bh = max(0.0, ymax - ymin)\n",
    "    if bw <= 0 or bh <= 0:\n",
    "        return None\n",
    "    x_center = (xmin + xmax) / 2.0 / W\n",
    "    y_center = (ymin + ymax) / 2.0 / H\n",
    "    bw /= W\n",
    "    bh /= H\n",
    "    return x_center, y_center, bw, bh\n",
    "\n",
    "# Group rows per (split, filename)\n",
    "bad, written = 0, 0\n",
    "for (split, fname), g in tqdm(df.groupby([\"split\", \"filename\"]), total=df.groupby([\"split\", \"filename\"]).ngroups):\n",
    "    img_path = resolve_image_path(fname)\n",
    "    if img_path is None:\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    # Label file path\n",
    "    stem = img_path.stem\n",
    "    lbl_fp = Path(YOLO_DIR)/split/\"labels\"/f\"{stem}.txt\"\n",
    "\n",
    "    # Build label lines\n",
    "    lines = []\n",
    "    W = float(g.iloc[0][\"width\"])\n",
    "    H = float(g.iloc[0][\"height\"])\n",
    "    for _, r in g.iterrows():\n",
    "        cid = name_to_id[str(r[\"class\"])]\n",
    "        xywh = xyxy_to_yolo(float(r[\"xmin\"]), float(r[\"ymin\"]), float(r[\"xmax\"]), float(r[\"ymax\"]), W, H)\n",
    "        if xywh is None:\n",
    "            continue\n",
    "        lines.append(f\"{cid} \" + \" \".join(f\"{v:.6f}\" for v in xywh))\n",
    "\n",
    "    if not lines:\n",
    "        # Skip images that ended up without any valid boxes\n",
    "        continue\n",
    "\n",
    "    # Write label file\n",
    "    with open(lbl_fp, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    written += 1\n",
    "\n",
    "    # Copy/link image to split/images\n",
    "    out_img = Path(YOLO_DIR)/split/\"images\"/img_path.name\n",
    "    try:\n",
    "        os.link(img_path, out_img)     # hard link (fast, saves space)\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.symlink(img_path, out_img)  # symlink fallback\n",
    "        except Exception:\n",
    "            shutil.copy2(img_path, out_img)  # last resort: copy\n",
    "\n",
    "print(f\"Images with labels written: {written}, missing/failed: {bad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:11:25.863368Z",
     "iopub.status.busy": "2025-09-27T08:11:25.863046Z",
     "iopub.status.idle": "2025-09-27T08:11:25.870135Z",
     "shell.execute_reply": "2025-09-27T08:11:25.869591Z",
     "shell.execute_reply.started": "2025-09-27T08:11:25.863344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Auto-generated for YOLOv8\n",
      "path: /kaggle/working/yolo_data    # dataset root\n",
      "train: train/images\n",
      "val:   val/images\n",
      "test:  test/images\n",
      "\n",
      "nc: 1\n",
      "names: ['plane']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_text = f\"\"\"# Auto-generated for YOLOv8\n",
    "path: {Path(YOLO_DIR).resolve()}    # dataset root\n",
    "train: train/images\n",
    "val:   val/images\n",
    "test:  test/images\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "with open(Path(YOLO_DIR)/\"data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(open(Path(YOLO_DIR)/\"data.yaml\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:11:31.373988Z",
     "iopub.status.busy": "2025-09-27T08:11:31.373404Z",
     "iopub.status.idle": "2025-09-27T08:42:09.320124Z",
     "shell.execute_reply": "2025-09-27T08:42:09.319304Z",
     "shell.execute_reply.started": "2025-09-27T08:11:31.373965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ━━━━━━━━━━━━ 21.5MB 167.7MB/s 0.1s0.1s<0.1s\n",
      "Ultralytics 8.3.203 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/yolo_data/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-military, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/yolov8n-military, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 16.5MB/s 0.0s\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 71.0MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 22.4±6.7 MB/s, size: 78.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_data/train/labels... 16457 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 16457/16457 359.0it/s 45.8s<0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolo_data/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.15G reserved, 0.12G allocated, 15.62G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    11135987       28.65         0.845         33.76         131.3        (1, 3, 640, 640)                    list\n",
      "    11135987       57.29         1.183         23.91            77        (2, 3, 640, 640)                    list\n",
      "    11135987       114.6         1.955         26.72           122        (4, 3, 640, 640)                    list\n",
      "    11135987       229.2         3.154         44.37         117.9        (8, 3, 640, 640)                    list\n",
      "    11135987       458.4         6.084         84.95         195.1       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 24 for CUDA:0 9.09G/15.89G (57%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 298.0±317.0 MB/s, size: 175.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_data/train/labels.cache... 16457 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 16457/16457 27.3Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 32.3±28.5 MB/s, size: 349.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_data/val/labels... 4026 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4026/4026 327.7it/s 12.3s<0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolo_data/val/labels.cache\n",
      "Plotting labels to /kaggle/working/runs/yolov8n-military/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/runs/yolov8n-military\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5      7.03G      1.102       1.24      1.279         64        640: 100% ━━━━━━━━━━━━ 686/686 2.2it/s 5:09<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.3it/s 36.4s0.3ss\n",
      "                   all       4026       7064      0.816       0.68      0.765      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5      7.03G       1.15      1.127      1.305         59        640: 100% ━━━━━━━━━━━━ 686/686 2.3it/s 5:02<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.4it/s 35.2s0.3ss\n",
      "                   all       4026       7064      0.831       0.69      0.783       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5      7.06G      1.089      1.037      1.273         59        640: 100% ━━━━━━━━━━━━ 686/686 2.3it/s 5:02<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.4it/s 34.6s0.3ss\n",
      "                   all       4026       7064      0.865      0.743      0.834      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5      7.09G     0.9408     0.8734      1.197         73        640: 100% ━━━━━━━━━━━━ 686/686 2.3it/s 4:60<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.4it/s 35.3s0.3ss\n",
      "                   all       4026       7064      0.891      0.797      0.877      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5      7.13G     0.8429     0.7543      1.141         52        640: 100% ━━━━━━━━━━━━ 686/686 2.3it/s 4:60<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.4it/s 35.1s0.3ss\n",
      "                   all       4026       7064      0.921      0.836      0.911      0.734\n",
      "\n",
      "5 epochs completed in 0.471 hours.\n",
      "Optimizer stripped from /kaggle/working/runs/yolov8n-military/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /kaggle/working/runs/yolov8n-military/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /kaggle/working/runs/yolov8n-military/weights/best.pt...\n",
      "Ultralytics 8.3.203 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 84/84 2.1it/s 39.8s0.4ss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4026       7064      0.922      0.836      0.911      0.734\n",
      "Speed: 0.1ms preprocess, 3.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/yolov8n-military\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Choose a model size: yolov8n.pt / yolov8s.pt / yolov8m.pt / yolov8l.pt / yolov8x.pt\n",
    "model = YOLO(\"yolov8s.pt\")   # pretrained COCO weights\n",
    "\n",
    "results = model.train(\n",
    "    data=str(Path(YOLO_DIR)/\"data.yaml\"),\n",
    "    imgsz=640,\n",
    "    epochs=5,\n",
    "    batch=-1,          # auto batch\n",
    "    device=0,\n",
    "    workers=8,\n",
    "    project=\"runs\",\n",
    "    name=\"yolov8n-military\",\n",
    "    cos_lr=True,\n",
    "    patience=30,\n",
    "    close_mosaic=10,   # stabilize late training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-27T08:51:17.636579Z",
     "iopub.status.busy": "2025-09-27T08:51:17.635396Z",
     "iopub.status.idle": "2025-09-27T08:51:19.992051Z",
     "shell.execute_reply": "2025-09-27T08:51:19.991292Z",
     "shell.execute_reply.started": "2025-09-27T08:51:17.636540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/out.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_to_zip = \"/kaggle/working/runs\"\n",
    "import shutil\n",
    "shutil.make_archive(\"out\", 'zip', dir_to_zip)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 821893,
     "sourceId": 13127594,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
